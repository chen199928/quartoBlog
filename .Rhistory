plt.show()
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
# Assuming X is your matrix of TF-IDF features
distortions = []
for i in range(1, 11):
km = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)
km.fit(sentences)
distortions.append(km.inertia_)
plt.plot(range(1, 11), distortions, marker='o')
plt.xlabel('Number of clusters')
plt.ylabel('Distortion')
plt.show()
# find cosine distance
# list for value of cosine distance from first sentence to the all other sentences
cosine_distance = list()
# find cosine distance distance from first sentence to the all other sentences
for i in range(row):
cosine_distance.append(cosine( word_matrix.loc[0],  word_matrix.loc[i]))
cosine_distance
# copy our list with cosine distances for further steps
cosine_distanceCopy = list(cosine_distance)
# create a list for the closest sentences and its value to the first sentences
closest = [[-1, 0], [-1, 0]]#-1 is the index of the closest sentence,its set to -1 initially .
# 0 is the cosine distance to the closest sentence. It's initialized to 0
# delete the minimum value in the copied list since it is equal to 0, which means the distance from the first sentence to the first
cosine_distanceCopy.remove(min(cosine_distanceCopy))
for i in range(2):
#(for the two closest sentences).
# find the minimum, that is, the closest sentence to the first one in the copied list and add to the list for the closest sentences
closest[i][1] = min(cosine_distanceCopy)
for j in range(len(cosine_distance)):
# find value of closest sentences in the original cosine list
if closest[i][1] == cosine_distance[j]:
closest[i][0] = j
# remove the found minimum to find the second one using the same method
cosine_distanceCopy.remove(min(cosine_distanceCopy))
closest
# plot the dendrogram
import scipy.cluster.hierarchy as model
dend_cos = model.dendrogram(model.linkage(matrix, method='complete', metric="cosine"), labels=matrix.index)
#The model.linkage() function performs hierarchical clustering on the given data (here, the matrix) using the complete linkage method, which is a method to compute the distance between clusters.
#The metric="cosine" argument specifies that the cosine distance should be used to measure the dissimilarity between the clusters. Cosine distance is a common choice when working with text data.
#The labels=matrix.index argument provides labels for the dendrogram, using the indices from the original matrix.
# copy our list with cosine distances for further steps
cosine_distanceCopy = list(cosine_distance)
# create a list for the closest sentences and its value to the first sentences
closest = [[-1, 0], [-1, 0]]#-1 is the index of the closest sentence,its set to -1 initially .
# 0 is the cosine distance to the closest sentence. It's initialized to 0
# delete the minimum value in the copied list since it is equal to 0, which means the distance from the first sentence to the first
cosine_distanceCopy.remove(min(cosine_distanceCopy))
for i in range(2):
#(for the two closest sentences).
# find the minimum, that is, the closest sentence to the first one in the copied list and add to the list for the closest sentences
closest[i][1] = min(cosine_distanceCopy)
for j in range(len(cosine_distance)):
# find value of closest sentences in the original cosine list
if closest[i][1] == cosine_distance[j]:
closest[i][0] = j
# remove the found minimum to find the second one using the same method
cosine_distanceCopy.remove(min(cosine_distanceCopy))
closest
# copy our list with cosine distances for further steps
cosine_distanceCopy = list(cosine_distance)
# create a list for the closest sentences and its value to the first sentences
closest = [[-1, 0], [-1, 0]]#-1 is the index of the closest sentence,its set to -1 initially .
# 0 is the cosine distance to the closest sentence. It's initialized to 0
# delete the minimum value in the copied list since it is equal to 0, which means the distance from the first sentence to the first
cosine_distanceCopy.remove(min(cosine_distanceCopy))
for i in range(2):
#(for the two closest sentences).
# find the minimum, that is, the closest sentence to the first one in the copied list and add to the list for the closest sentences
closest[i][1] = min(cosine_distanceCopy)
for j in range(len(cosine_distance)):
# find value of closest sentences in the original cosine list
if closest[i][1] == cosine_distance[j]:
closest[i][0] = j
# remove the found minimum to find the second one using the same method
cosine_distanceCopy.remove(min(cosine_distanceCopy))
closest
# plot the dendrogram
import scipy.cluster.hierarchy as model
dend_cos = model.dendrogram(model.linkage(matrix, method='complete', metric="cosine"), labels=matrix.index)
#The model.linkage() function performs hierarchical clustering on the given data (here, the matrix) using the complete linkage method, which is a method to compute the distance between clusters.
#The metric="cosine" argument specifies that the cosine distance should be used to measure the dissimilarity between the clusters. Cosine distance is a common choice when working with text data.
#The labels=matrix.index argument provides labels for the dendrogram, using the indices from the original matrix.
# plot the dendrogram
import scipy.cluster.hierarchy as model
dend_cos = model.dendrogram(model.linkage(matrix, method='complete', metric="cosine"), labels=matrix.index)
#The model.linkage() function performs hierarchical clustering on the given data (here, the matrix) using the complete linkage method, which is a method to compute the distance between clusters.
#The metric="cosine" argument specifies that the cosine distance should be used to measure the dissimilarity between the clusters. Cosine distance is a common choice when working with text data.
#The labels=matrix.index argument provides labels for the dendrogram, using the indices from the original matrix.
dend_cos
plt.figure()
# Generate the linkage matrix
Z = model.linkage(matrix, method='complete', metric="cosine")
# Create a new figure
fig = plt.figure(figsize=(5, 5))
# Create a dendrogram
dn = dendrogram(Z)
# Display the dendrogram)
plt.show()
plt.figure()
# Generate the linkage matrix
Z = model.linkage(matrix, method='average', metric="cosine")
# Create a new figure
fig = plt.figure(figsize=(5, 5))
# Create a dendrogram
dn = dendrogram(Z)
# Display the dendrogram)
plt.show()
plt.figure()
# Generate the linkage matrix
Z = model.linkage(matrix, method='average', metric="euclidean")
# Create a new figure
fig = plt.figure(figsize=(5, 5))
# Create a dendrogram
dn = dendrogram(Z)
# Display the dendrogram)
plt.show()
plt.figure()
# Generate the linkage matrix
Z = model.linkage(matrix, method='single', metric="cosine")
# Create a new figure
fig = plt.figure(figsize=(5, 5))
# Create a dendrogram
dn = dendrogram(Z)
# Display the dendrogram)
plt.show()
plt.figure()
# Generate the linkage matrix
Z = model.linkage(matrix, method='single', metric="cosine")
# Create a new figure
fig = plt.figure(figsize=(5, 10))
# Create a dendrogram
dn = dendrogram(Z)
# Display the dendrogram)
plt.show()
# find cosine distance
# list for value of cosine distance from first sentence to the all other sentences
cosine_distance = list()
# find cosine distance distance from first sentence to the all other sentences
for i in range(row):
cosine_distance.append(cosine( word_matrix.loc[0],  word_matrix
# find cosine distance
# list for value of cosine distance from first sentence to the all other sentences
cosine_distance = list()
# find cosine distance distance from first sentence to the all other sentences
for i in range(row):
cosine_distance.append(cosine( word_matrix.loc[0],  word_matrix[i]))
# find cosine distance
# list for value of cosine distance from first sentence to the all other sentences
cosine_distance = list()
# find cosine distance distance from first sentence to the all other sentences
for i in range(row):
cosine_distance.append(cosine( word_matrix.loc[0],  word_matrix.loc[i]))
cosine_distance
plt.figure()
# Generate the linkage matrix
Z = model.linkage(matrix, method='ward', metric="cosine")
# Create a new figure
fig = plt.figure(figsize=(5, 10))
# Create a dendrogram
dn = dendrogram(Z)
# Display the dendrogram)
plt.show()
# find cosine distance
# list for value of cosine distance from first sentence to the all other sentences
cosine_distance = list()
# find cosine distance distance from first sentence to the all other sentences
for i in range(row):
cosine_distance.append(cosine( word_matrix.loc[1],  word_matrix.loc[i]))
cosine_distance
# find cosine distance
# list for value of cosine distance from first sentence to the all other sentences
cosine_distance = list()
# find cosine distance distance from first sentence to the all other sentences
for i in range(row):
cosine_distance.append(cosine( word_matrix.loc[1],  word_matrix.loc[i]))
cosine_distance
# copy our list with cosine distances for further steps
cosine_distanceCopy = list(cosine_distance)
# create a list for the closest sentences and its value to the first sentences
closest = [[-1, 0], [-1, 0]]#-1 is the index of the closest sentence,its set to -1 initially .
# 0 is the cosine distance to the closest sentence. It's initialized to 0
# delete the minimum value in the copied list since it is equal to 0, which means the distance from the first sentence to the first
cosine_distanceCopy.remove(min(cosine_distanceCopy))
for i in range(2):
#(for the two closest sentences).
# find the minimum, that is, the closest sentence to the first one in the copied list and add to the list for the closest sentences
closest[i][1] = min(cosine_distanceCopy)
for j in range(len(cosine_distance)):
# find value of closest sentences in the original cosine list
if closest[i][1] == cosine_distance[j]:
closest[i][0] = j
# remove the found minimum to find the second one using the same method
cosine_distanceCopy.remove(min(cosine_distanceCopy))
closest
plt.figure()
# Generate the linkage matrix
Z = model.linkage(matrix, method='simple', metric="cosine")
# Create a new figure
fig = plt.figure(figsize=(5, 10))
# Create a dendrogram
dn = dendrogram(Z)
# Display the dendrogram)
plt.show()
plt.figure()
# Generate the linkage matrix
Z = model.linkage(matrix, method='simple', metric="cosine")
# Create a new figure
fig = plt.figure(figsize=(5, 10))
# Create a dendrogram
dn = dendrogram(Z)
# Display the dendrogram)
plt.show()
# find cosine distance
# list for value of cosine distance from first sentence to the all other sentences
cosine_distance = list()
# find cosine distance distance from first sentence to the all other sentences
for i in range(row):
cosine_distance.append(cosine( word_matrix.loc[2],  word_matrix.loc[i]))
# copy our list with cosine distances for further steps
cosine_distanceCopy = list(cosine_distance)
# create a list for the closest sentences and its value to the first sentences
closest = [[-1, 0], [-1, 0]]#-1 is the index of the closest sentence,its set to -1 initially .
# 0 is the cosine distance to the closest sentence. It's initialized to 0
# delete the minimum value in the copied list since it is equal to 0, which means the distance from the first sentence to the first
cosine_distanceCopy.remove(min(cosine_distanceCopy))
for i in range(2):
#(for the two closest sentences).
# find the minimum, that is, the closest sentence to the first one in the copied list and add to the list for the closest sentences
closest[i][1] = min(cosine_distanceCopy)
for j in range(len(cosine_distance)):
# find value of closest sentences in the original cosine list
if closest[i][1] == cosine_distance[j]:
closest[i][0] = j
# remove the found minimum to find the second one using the same method
cosine_distanceCopy.remove(min(cosine_distanceCopy))
closest
plt.figure()
# Generate the linkage matrix
Z = model.linkage(matrix, method='simple', metric="cosine")
# Create a new figure
fig = plt.figure(figsize=(5, 10))
# Create a dendrogram
dn = dendrogram(Z)
# Display the dendrogram)
plt.show()
# Create a list of tuples where each tuple is (index, distance)
indexed_distances = list(enumerate(cosine_distance))
# Sort the list by distance
sorted_distances = sorted(indexed_distances, key=lambda x: x[1])
# Get the two smallest distances, excluding the first one (which is 0)
closest_sentences = sorted_distances[1:3]
closest_sentences
# Create a list of tuples where each tuple is (index, distance)
indexed_distances = list(enumerate(cosine_distance))
# Sort the list by distance
sorted_distances = sorted(indexed_distances, key=lambda x: x[1])
# Get the two smallest distances, excluding the first one (which is 0)
closest_sentences = sorted_distances[1:3]
closest_sentences
from scipy.spatial.distance import cosine
# Calculate cosine distances from the third sentence to all other sentences
cosine_distance = [cosine(word_matrix.loc[2], word_matrix.loc[i]) for i in range(row)]
cosine_distance
# find cosine distance
# list for value of cosine distance from first sentence to the all other sentences
cosine_distance = list()
# find cosine distance distance from first sentence to the all other sentences
for i in range(row):
cosine_distance.append(cosine( word_matrix.loc[2],  word_matrix.loc[i]))
cosine_distance
# find cosine distance
# list for value of cosine distance from first sentence to the all other sentences
cosine_distance = list()
# find cosine distance distance from first sentence to the all other sentences
for i in range(row):
cosine_distance.append(cosine( word_matrix.loc[2],  word_matrix.loc[i]))
# find cosine distance
# list for value of cosine distance from first sentence to the all other sentences
cosine_distance = list()
# find cosine distance distance from first sentence to the all other sentences
for i in range(row):
cosine_distance.append(cosine( word_matrix.loc[2],  word_matrix.loc[i]))
cosine_distance
# Create a list of tuples where each tuple is (index, distance)
indexed_distances = list(enumerate(cosine_distance))
# Sort the list by distance
sorted_distances = sorted(indexed_distances, key=lambda x: x[1])
# Get the two smallest distances, excluding the first one (which is 0)
closest_sentences = sorted_distances[1:3]
closest_sentences
from scipy.spatial.distance import cosine
# Calculate cosine distances from the third sentence to all other sentences
cosine_distance = [cosine(word_matrix.loc[2], word_matrix.loc[i]) for i in range(row)]
cosine_distance
# Create a list of tuples where each tuple is (index, distance)
indexed_distances = list(enumerate(cosine_distance))
# Sort the list by distance
sorted_distances = sorted(indexed_distances, key=lambda x: x[1])
# Get the two smallest distances, excluding the first one (which is 0)
closest_sentences = sorted_distances[1:3]
closest_sentences
plt.figure()
# Generate the linkage matrix
Z = model.linkage(matrix, method='simple', metric="cosine")
# Create a new figure
fig = plt.figure(figsize=(5, 10))
# Create a dendrogram
dn = dendrogram(Z)
# Display the dendrogram)
plt.show()
plt.figure()
# Generate the linkage matrix
Z = linkage(matrix, method='simple', metric="cosine")
# Create a new figure
fig = plt.figure(figsize=(5, 10))
# Create a dendrogram
dn = dendrogram(Z)
# Display the dendrogram)
plt.show()
# Generate the linkage matrix
Z = model.linkage(matrix, method='simple', metric="cosine")
# Create a new figure
fig = plt.figure(figsize=(5, 10))
# Create a dendrogram
dn = dendrogram(Z)
# Display the dendrogram)
plt.show()
matrix = pd.DataFrame(unique_words, range(len(tokenized_sentences)))
row, col = matrix.shape
matrix.shape
matrix
len(unique_words)
matrix = pd.DataFrame(unique_words, range(len(tokenized_sentences)))
row, col = matrix.shape
matrix.shape
matrix
len(unique_words)
range(len(tokenized_sentences))
matrix = pd.DataFrame(unique_words, range(len(tokenized_sentences)))
row, col = matrix.shape
matrix.shape
matrix
len(unique_words)
range(len(tokenized_sentences))
row
col
matrix = pd.DataFrame(unique_words, range(len(tokenized_sentences)))
row, col = matrix.shape
matrix.shape
matrix
len(unique_words)
len(tokenized_sentences)
row
col
for i in range(len(tokenized_sentences)):
for j in range(len(unique_words)):
matrix.iloc[i, j] = 0
for i in range(len(tokenized_sentences)):
for word in tokenized_sentences[i]:
matrix.loc[i, word] += 1
matrix
document_df = pd.DataFrame(unique_words, index=pd.RangeIndex(start=0, stop=len(clean_sentences)))
# Get the number of rows and columns
rows, columns = document_df.shape
for i in range(rows):
for j in range(columns):
matrix.iloc[i, j] = 0
for i in range(len(tokenized_sentences)):
for word in tokenized_sentences[i]:
matrix.loc[i, word] += 1
matrix
document_df = pd.DataFrame(unique_words, index=pd.RangeIndex(start=0, stop=len(clean_sentences)))
# Get the number of rows and columns
rows, columns = document_df.shape
for i in range(rows):
for j in range(columns):
document_df.iloc[i, j] = 0
for i in range(len(tokenized_sentences)):
for word in tokenized_sentences[i]:
document_df.loc[i, word] += 1
document_df
# Initialize the unique words dictionary and the clean sentences list
unique_words = {}
tokenized_sentences = []
# Initialize the unique word index
word_index = 0
# Process each sentence
for sentence in sentences:
# Convert to lower case
sentence = sentence.lower()
# Tokenize the sentence
words = re.split('[^a-z]', sentence)
# Remove empty words
words = [word for word in words if word]
# Add the cleaned sentence to the list
tokenized_sentences.append(words)
# Add unique words to the dictionary
for word in words:
if word not in unique_words:
unique_words[word] = word_index
word_index += 1
len(tokenized_sentences)
# Initialize the unique words dictionary and the clean sentences list
unique_words = {}
tokenized_sentences = []
word_index = 0
# Process each sentence
for sentence in sentences:
# Convert to lower case
sentence = sentence.lower()
# Tokenize the sentence
words = re.split('[^a-z]', sentence)
# Remove empty words
words = [word for word in words if word]
# Add the cleaned sentence to the list
tokenized_sentences.append(words)
# Add unique words to the dictionary
for word in words:
if word not in unique_words:
unique_words[word] = word_index
word_index += 1
len(tokenized_sentences)
unique_words
# Initialize the unique words dictionary and the clean sentences list
unique_words = set()
tokenized_sentences = []
word_index = 0
# Process each sentence
for sentence in sentences:
# Convert to lower case
sentence = sentence.lower()
# Tokenize the sentence
words = re.split('[^a-z]', sentence)
# Remove empty words
words = [word for word in words if word]
# Add the cleaned sentence to the list
tokenized_sentences.append(words)
# Add unique words to the dictionary
unique_words.update(words)
len(tokenized_sentences)
unique_words
sentences_df = pd.DataFrame(index=range(len(tokenized_sentences)), columns=unique_word)
# Initialize all values in the DataFrame to zero
sentences_df.fillna(0, inplace=True)
# Iterate over all sentences
for idx, sentence in enumerate(tokenized_sentences):
# Increment the count for each word in the sentence
for word in sentence:
sentences_df.loc[idx, word] += 1
sentences_df
sentences_df = pd.DataFrame(index=range(len(tokenized_sentences)), columns=unique_words)
# Initialize all values in the DataFrame to zero
sentences_df.fillna(0, inplace=True)
# Iterate over all sentences
for idx, sentence in enumerate(tokenized_sentences):
# Increment the count for each word in the sentence
for word in sentence:
sentences_df.loc[idx, word] += 1
sentences_df
sentences_df = pd.DataFrame(index=range(len(tokenized_sentences)), columns=list(unique_words))
# Initialize all values in the DataFrame to zero
sentences_df.fillna(0, inplace=True)
# Iterate over all sentences
for idx, sentence in enumerate(tokenized_sentences):
# Increment the count for each word in the sentence
for word in sentence:
sentences_df.loc[idx, word] += 1
sentences_df
unique_words = set()
tokenized_sentences = []
# Process each sentence
for sentence in sentences:
sentence = sentence.lower()
words = re.split('[^a-z]', sentence)
words = [word for word in words if word]
tokenized_sentences.append(words)
unique_words.update(words)
unique_words
tokenized_sentences
with open('words.txt', 'r') as file:
sentences = file.readlines()
sentences
import re
from collections import Counter
import pandas as pd
import numpy as np
from sklearn.cluster import AgglomerativeClustering
from sklearn.feature_extraction.text import TfidfVectorizer
from scipy.cluster.hierarchy import dendrogram, linkage
from matplotlib import pyplot as plt
from scipy.spatial.distance import cosine
num_rows = sentences_df.shape[0]
# Calculate cosine distances from the third sentence to all other sentences
cosine_distance = [cosine(sentences_df.loc[2], sentences_df.loc[i]) for i in range(num_rows)]
cosine_distance
num_rows = sentences_df.shape[0]
# Calculate cosine distances from the third sentence to all other sentences
cosine_distance = [cosine(sentences_df.loc[2], sentences_df.loc[i]) for i in range(num_rows)]
cosine_distance
indexed_distances = list(enumerate(cosine_distance))
sorted_distances = sorted(indexed_distances, key=lambda x: x[1])
closest_sentences = sorted_distances[1:3]
closest_sentences
sorted_distances
indexed_distances = list(enumerate(cosine_distance))
sorted_distances = sorted(indexed_distances, key=lambda x: x[1])
closest_sentences = sorted_distances[1:3]
closest_sentences
